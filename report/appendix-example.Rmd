<!-- The following code should appear at the beginning of the first appendix.
After that, all subsequent sections will be turned into appendices. -->

`r if(knitr:::is_latex_output()) '\\Appendices'`

`r if(!knitr:::is_latex_output()) '# (APPENDIX) Appendix {-}'`

# Shortraker Rockfish {#app:shortraker-appendix}

This appendix outlines the setup and implementation of the  Shortraker rockfish (*Sebastes borealis*) operating model. This is an example of the methods and is not intended for use in fisheries management decision making.

## Stock parameters

The first step is to load the data into the workspace using functions from the *gfplot* package. Here, *d* contains *catch*, *commercial_samples*, *survey_samples* and *survey_index*.

```{r, message=FALSE, warning=FALSE, results='hide', echo = 9 }
n_iters <- 50

# Set up data - d will contain the data for commercial samples, survey, and catch
science_name <- "Sebastes borealis"
species_name <- "shortraker rockfish"
species_dir <- file.path(here::here("analysis",
                                    paste0(gsub(" ",
                                                "-",
                                                species_name))))
if(!data_file_exists(species_name)){
  fetch_data(species_name)
}
d <- load_data(species_name)
d <- readRDS("../generated-data/shortraker-rockfish.rds")
lw <- rfishbase::length_weight(science_name)
```

Start with the generic Rockfish *Stock* object template.

```{r echo = TRUE}
stock <- DLMtool::Rockfish
```

**Name, Common_Name, Species**

```{r echo = TRUE}
stock@Name <- firstup(species_name)
stock@Common_Name <- firstup(species_name)
stock@Species <- firstup(science_name)
```

**maxage**

@love2002 note that `r species_name` have been aged at 157 years. `r firstup(species_name)` have been aged to by DFO in the past. Let's pull the maximum age from GFBio:

*Not necessarily reliable because ageing very uncertain; probably should look at some upper quantile or take value from elsewhere*

```{r echo = TRUE}
stock@maxage <- max(d$survey_samples$age, d$commercial_samples$age, na.rm = TRUE)
```

**M**

@echave2015 estimate natural mortality in the Gulf of Alaska to be 0.03. Let's place some relatively wide bounds around that.

```{r echo = TRUE}
stock@M <- c(0.02, 0.10)
```

**Perr**

@thorson2014 finds the mean SD of recruitment deviations in log space to be ballpark 0.6--0.8. Need to look for data in other assessments of similar rockfish species or of shortraker in other regions.

```{r echo = TRUE}
stock@Perr <- c(0.2, 0.8)
```

**Linf, K, t0**

Maximum length: @love2002 list the maximum size as 120 cm. They also note that in the Gulf of Alaska fish smaller than 35 cm are rarely found. Fishbase lists a maximum length of `r max(lw$LengthMax)` cm. However, we can fit von Bertalanffy growth curves to the length-age data in GFBio.

<!-- Because we are providing our own samples from the model posterior, we provide these values using the custom parameters functionality in the `cpar` slot of the final operating model. -->

```{r echo = TRUE}
x <- bind_samples(dat_survey = d$survey_samples,
                  dat_comm = d$commercial_samples)
x <- x[!duplicated(x$specimen_id), ]
x <- dplyr::filter(x, major_stat_area_name != "4B: STRAIT OF GEORGIA")
vb_m <- fit_vb(x, "male", method = "mcmc", iter = 2000, chains = 1, cores = 4)
vb_f <- fit_vb(x, "female", method = "mcmc", iter = 2000, chains = 1, cores = 4)
vonb <- fit_vb(x, "all", method = "mcmc", iter = 2000, chains = 1, cores = 4)
vb <- vonb$model %>%
  as.data.frame() %>%
  as_tibble()
stock@Linf <- median(vb$linf)
stock@K <- median(vb$k)
stock@t0 <- median(vb$t0)
plot_vb(object_female = vb_f, object_male = vb_m) +
  guides(colour = FALSE, fill = FALSE, lty = FALSE)
```

<!-- Let's try fitting VB models that permit a specified level of aging measurement error. We will specify this level of measurement error with a CV. -->

<!-- ```{r echo = TRUE} -->
<!-- x <- x %>% -->
<!--   mutate(cv_age = 0.2) -->
<!-- vb_err <- fit_vb(x, -->
<!--                  "all", -->
<!--                  method = "mcmc", -->
<!--                  iter = 2000, -->
<!--                  chains = 1, -->
<!--                  cores = 4) -->

<!-- ``` -->

<!-- #Kgrad - TODO - NO LONGER USED ACCORDING TO DOCUMENTATION -->

<!-- Mean temporal trend in growth parameter K, expressed as a percentage change in K per year. We leave it at the default of ranging between -0.25% and 0.25% per year. -->

<!-- ```{r echo = TRUE} -->
<!-- stock@Kgrad <- c(-0.0025, 0.0025) -->
<!-- ``` -->


<!-- #LKinfgrad - TODO - NO LONGER USED ACCORDING TO DOCUMENTATION -->
<!-- Range of annual percent change in L infinity. Use guess of +/- 1% for now. -->

<!-- ```{r echo = TRUE} -->
<!-- stock@Linfgrad <- c(-0.1, 0.1) -->
<!-- ``` -->

<!-- Autocorrelation in recruitment deviations rec(t) = AC*rec(t-1)+(1-AC)*sigma(t). The default is a wide range, `r stock@AC`. @thorson2014 find that autocorrelation of recruitment deviations is probably around 0.45. Barring better information in the literature, let's leave the default wide range: -->

<!-- ```{r echo = TRUE} -->
<!-- stock@AC -->
<!-- ``` -->

**L50**

@love2002 p. 136 list length at 50% maturity of 45 cm for both sexes off of West Vancouver Island and this value may be cited from @dfo1999. @conrath2017 recently sampled 357 shortraker rockfish in the Gulf of Alaska. They note that they doubt there is substantial regional variation in these maturity parameters for these species. They calculated L50 as 49.4 cm with a 95% CI of 47.9--50.8 cm.

**2018-03-29: should use values from the model fits to our data in other document**

```{r echo = TRUE}
stock@L50 <- c(48, 51)
```

**L50_95**

Figure 5 in @conrath2017 shows the proportion mature by length. 95% are mature by approximately 60 cm. 60 cm - 49 cm = 11cm. So, we set `L50_95` to approximately 11 cm with a small, 2 cm uncertainty buffer.

**2018-03-29: should use values from the model fits to our data in other document**

```{r echo = TRUE}
stock@L50_95 <- c(9, 13)
```

**a**

Using the mean value from Fishbase. Alternatively, we could use the value cited in @love2002 (a = 0.0098, b = 3.130), which is based on Martin (1997) (reference found within @love2002). Values within @love2011 are even lower.

**2018-03-29: should use values from the model fits to our data in other document**

```{r echo = TRUE}
lw <- rfishbase::length_weight(science_name)
lw$a
mean(lw$a)
stock@a <- mean(lw$a)
```

**b**

Using the mean value from Fishbase.

```{r echo = TRUE}
lw$b
mean(lw$b)
stock@b <- mean(lw$b)
```

<!-- Current level of stock depletion (Bcurrent/Bunfished). We need to put some thought into this still: TODO -->

<!-- ```{r echo = TRUE} -->
<!-- stock@D -->
<!-- ``` -->

**Size_area_1**

Area 1 represents the size of the area outside the range of fishing. We put 10% of individuals in area 1 and 90% in area 2. TODO

```{r echo = TRUE}
stock@Size_area_1 <- c(0.1, 0.9)
```

**Frac_area_1**

Area 1 represents habitat outside of the range of fishing. We put 10% of individuals in area 1 and 90% in area 2. TODO

```{r echo = TRUE}
stock@Frac_area_1 <- stock@Size_area_1
```

**Prob_staying**

This is a guess for now. TODO

```{r echo = TRUE}
stock@Prob_staying <- c(0.85, 0.95)
```

**Fdisc**

For `r species_name`, and most rockfish, this value should be at or near 100%.

```{r echo = TRUE}
stock@Fdisc <- c(1, 1)
```

**Source**

Modify this to mention that it is a modification of the rockfish model template.

```{r echo = TRUE}
stock@Source <- paste(c("A modification of a rockfish model based on",
  stock@Source), collapse = " ")
```

## Constructing the operating model

Let's combine the stock, fleet, observation, and implementation objects into a complete operating model:

```{r echo = TRUE}
short_om <- new('OM', stock, Generic_Fleet, Imprecise_Unbiased, Perfect_Imp)
MPs <- c("DCAC", "DCAC_40", "DCAC_ML", "DBSRA_40",
  "DCAC4010", "DBSRA4010", "DBSRA", "CC1", "CC4")
short_om@nsim <- n_iters
```

Let's now add the custom parameters:

```{r echo = TRUE}
short_om@cpars$Linf <- stock@Linf
short_om@cpars$K <- stock@K
short_om@cpars$t0 <- stock@t0
short_om@maxage <- stock@maxage
```

There are a variety of built-in plotting functions to examine the components of the operating model:

```{r, eval=FALSE}
plotStock(short_om, nsamp = 3, incVB = FALSE)

# pdf(file.path(figures_dir, "ex-stock.pdf"), width = 10, height = 12)
# plotStock(short_om, nsamp = 3, incVB = FALSE)
# dev.off()
```

```{r, eval=FALSE}
plotSelect(short_om, sim = 1) # one sample, others will look different
```

```{r, eval=FALSE}
plotFleet(GenericFfleet, Stock = stock)

# pdf(file.path(figures_dir, "ex-fleet.pdf"), width = 10, height = 12)
# plotFleet(Generic_Fleet, Stock = stock)
# dev.off()
```

```{r, eval=FALSE}
plotImp(Perfect_Imp)
```

```{r, eval=FALSE, fig.height=9}
plotObs(Imprecise_Unbiased)

# pdf(file.path(figures_dir, "imprecise-unbiased.pdf"), width = 10, height = 12)
# plotObs(Imprecise_Unbiased)
# dev.off()
```

Or we can create all the plots at once:

```{r, fig.height=9, fig.width=10}
plot(short_om)

# pdf(file.path(figures_dir, "ex-om-all.pdf"), width = 10, height = 12)
# plot(short_om)
# dev.off()
```

Now we can run closed-loop simulation:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
if(!exists("short_mse")){
  DLMtool::setup(cpus = parallel::detectCores())
  short_mse <- runMSE(OM = short_om, MPs = MPs)
}
```

And examine the output.

```{r}
oldpar <- par()
plot(short_mse)
oldpar <- par()
##DFO_hist(short_mse)
DFO_plot(short_mse)
DFO_plot2(short_mse)
```

```{r, fig.height=9, warning=FALSE}
DFO_proj(short_mse)
#DFO_hist(short_om)
DFO_plot2(short_mse)

# d <- DFO_plot2(short_mse)
# ggplot(d, aes(B50/100, LTY/100, label = MPs, colour = Satisfice)) +
#   geom_vline(xintercept = 0.5, col = "grey50") +
#   geom_hline(yintercept = 0.5, col = "grey50") +
#   geom_text() + ggsidekick::theme_sleek() +
#   scale_colour_manual(values = c("grey60", "black")) +
#   guides(colour = FALSE) +
#   xlab(expression(Pr(B>0.5~B[MSY]))) +
#   ylab(expression(Pr(yield>0.5~yield~at~F[MSY]))) +
#   xlim(0, 1) + ylim(0, 1)
```

```{r}
yend <- max(short_mse@proyears)
ffmsy <- short_mse@F_FMSY[,,yend]
bbmsy <- short_mse@B_BMSY[,,yend]

ffmsy <- reshape2::melt(ffmsy) %>%
  dplyr::rename(iter = Var1, mp = Var2, ffmsy = value)
bbmsy <- reshape2::melt(bbmsy) %>%
  dplyr::rename(iter = Var1, mp = Var2, bbmsy = value)

d <- dplyr::inner_join(ffmsy, bbmsy)

n <- data.frame(mp = 1:length(short_mse@MPs), mp_name = short_mse@MPs)
# n$mp_name <- paste(1:nrow(n), n$mp_name)

d <- dplyr::left_join(d, n)

ggplot(dplyr::filter(d, !mp_name %in% c("CC4", "DBSRA_ML")), aes(bbmsy, ffmsy)) +
  geom_vline(xintercept = c(0.4, 0.8), alpha = 0.2) +
  geom_hline(yintercept = 1, alpha = 0.2) +
  geom_density_2d(aes(colour = ..level..), bins = 5) +
  viridis::scale_colour_viridis() +
  ggsidekick::theme_sleek() +
  facet_wrap(~mp_name) +
  ylim(0, 3.5) + xlim(0, 3.5) +
  geom_point(alpha = 0.2) +
  labs(colour = "Prob. density", x = expression(B/B[MSY]),
    y = expression(F/F[MSY])) +
  guides(colour = FALSE)
#ggsave("analysis/short-bbmsy-ffmsy-multi.pdf", width = 8, height = 8)

ggplot(dplyr::filter(d, mp_name == c("DBSRA")), aes(bbmsy, ffmsy)) +
  geom_vline(xintercept = c(0.4, 0.8), alpha = 0.2) +
  geom_hline(yintercept = 1, alpha = 0.2) +
  geom_density_2d(aes(colour = ..level..), bins = 5) +
  viridis::scale_colour_viridis() +
  ggsidekick::theme_sleek() +
  facet_wrap(~mp_name) +
  ylim(0, 2.2) + xlim(0, 2.2) +
  geom_point(alpha = 0.2) +
  labs(colour = "Prob. density", x = expression(B/B[MSY]),
    y = expression(F/F[MSY])) +
  guides(colour = FALSE)
#ggsave("analysis/short-bbmsy-ffmsy-dbsra.pdf", width = 4, height = 4)
```

```{r}
ffmsy <- short_mse@F_FMSY[,,] %>% reshape2::melt() %>%
  dplyr::rename(iter = Var1, mp = Var2, ffmsy = value, year = Var3)
bbmsy <- short_mse@B_BMSY[,,] %>% reshape2::melt() %>%
  dplyr::rename(iter = Var1, mp = Var2, bbmsy = value, year = Var3)
d <- dplyr::inner_join(ffmsy, bbmsy)
d <- dplyr::left_join(d, n)
d <- reshape2::melt(d, id.vars = c("iter", "mp", "year", "mp_name"))
levels(d$variable) <- c(expression(F/F[MSY]), expression(B/B[MSY]))

d_median <- d %>% group_by(mp_name, year, variable) %>%
  summarise(median_value = median(value)) %>%
  mutate(iter = NA)

fudge <- 3.5
d$over <- FALSE
d$over[d$value > fudge] <- TRUE
d$value[d$over] <- fudge
d_median$median_value[d_median$median_value > fudge] <- fudge

d_last <- dplyr::filter(d, year == max(year)) %>%
  select(-over, -year) %>%
  rename(last_value = value)
d <- inner_join(d, d_last)

cols <- brewer.pal(3, "RdBu")
cols[2] <- "grey80"

plot_timeseries <- function(dat, dat_median, title = "",
  ylim = c(0, fudge), cols, values, labels = TRUE, yaxis = TRUE) {
  g <- ggplot(dat, aes_string("year", "value", group = "iter")) +
    geom_line(aes_string(colour = "last_value"), alpha = 0.3) +
    facet_grid(mp_name~., labeller = label_parsed) +
    ggsidekick::theme_sleek() +
    scale_colour_gradientn(colours = cols,
      values = values) +
    geom_line(data = dat_median, aes_string("year", "median_value"),
      colour = "black", lwd = 1.5) +
    ylim(ylim[1], ylim[2]) +
    ggtitle(title) +
    guides(colour = FALSE) +
    ylab("Value") + xlab("Year")

  if (!labels)
    g <- g + theme(strip.background = element_blank(),
      strip.text.y = element_blank())

  if (!yaxis)
    g <- g + theme(axis.text.y = element_blank())
  g
}

cols <- brewer.pal(5, "RdBu")
cols <- c(cols[1], "grey50", cols[length(cols)])
set.seed(42)
d_ <- filter(d, iter %in% sample(seq_len(max(d$iter)), 30))

# plot_timeseries(d, d_median,
# cols = cols, values = scales::rescale(c(0, 0.8, 1.2, fudge)))

mps <- c("CC1", "DBSRA")
p1 <- plot_timeseries(filter(d_, variable == "B/B[MSY]", mp_name %in% mps),
  filter(d_median, variable == "B/B[MSY]", mp_name %in% mps), expression(B/B[MSY]),
  cols = cols, values = scales::rescale(c(0, 0.8, 1.2, fudge)),
  labels = TRUE)
p2 <- plot_timeseries(filter(d_, variable == "F/F[MSY]", mp_name %in% mps),
  filter(d_median, variable == "F/F[MSY]", mp_name %in% mps), expression(F/F[MSY]),
  cols = cols, values = scales::rescale(c(fudge, 1.2, 0.8, 0)),
  labels = TRUE, yaxis = TRUE)
gridExtra::grid.arrange(p1, p2, ncol = 2)

# pdf("analysis/short-bbmsy-ffmsy-ts-ex.pdf", width = 6, height = 3.5)
# gridExtra::grid.arrange(p1, p2, ncol = 2)
# dev.off()

mps <- unique(d_$mp_name)
mps <- mps[-which(mps %in% c("CC4"))]
p1 <- plot_timeseries(filter(d_, variable == "B/B[MSY]", mp_name %in% mps),
  filter(d_median, variable == "B/B[MSY]", mp_name %in% mps), expression(B/B[MSY]),
  cols = cols, values = scales::rescale(c(0, 0.8, 1.2, fudge)),
  labels = TRUE)
p2 <- plot_timeseries(filter(d_, variable == "F/F[MSY]", mp_name %in% mps),
  filter(d_median, variable == "F/F[MSY]", mp_name %in% mps), expression(F/F[MSY]),
  cols = cols, values = scales::rescale(c(fudge, 1.2, 0.8, 0)),
  labels = TRUE, yaxis = TRUE)
# gridExtra::grid.arrange(p1, p2, ncol = 2)

# pdf("analysis/short-bbmsy-ffmsy-ts-ex-all.pdf", width = 6, height = 6)
# gridExtra::grid.arrange(p1, p2, ncol = 2)
# dev.off()

mps <- unique(d_$mp_name)
mps <- mps[-which(mps %in% c("CC4"))]
p1 <- plot_timeseries(filter(d_, variable == "B/B[MSY]", mp_name %in% mps),
  filter(d_median, variable == "B/B[MSY]", mp_name %in% mps), expression(B/B[MSY]),
  cols = cols, values = scales::rescale(c(0, 0.8, 1.2, fudge)),
  labels = TRUE)
p2 <- plot_timeseries(filter(d_, variable == "F/F[MSY]", mp_name %in% mps),
  filter(d_median, variable == "F/F[MSY]", mp_name %in% mps), expression(F/F[MSY]),
  cols = cols, values = scales::rescale(c(fudge, 1.2, 0.8, 0)),
  labels = TRUE, yaxis = TRUE)
# gridExtra::grid.arrange(p1, p2, ncol = 2)

# pdf("analysis/short-bbmsy-ffmsy-ts-ex-all.pdf", width = 6, height = 6)
# gridExtra::grid.arrange(p1, p2, ncol = 2)
# dev.off()

#########3
ffmsy <- short_mse@F_FMSY[,,] %>% reshape2::melt() %>%
  dplyr::rename(iter = Var1, mp = Var2, ffmsy = value, year = Var3)
bbmsy <- short_mse@B_BMSY[,,] %>% reshape2::melt() %>%
  dplyr::rename(iter = Var1, mp = Var2, bbmsy = value, year = Var3)
d <- dplyr::inner_join(ffmsy, bbmsy)
d <- dplyr::left_join(d, n)
d <- reshape2::melt(d, id.vars = c("iter", "mp", "year", "mp_name"))
levels(d$variable) <- c(expression(F/F[MSY]), expression(B/B[MSY]))

d_sum <- d %>% group_by(mp_name, year, variable) %>%
  summarise(median_value = median(value),
    l = quantile(value, probs = 0.75),
    u = quantile(value, probs = 0.25),
    ll = quantile(value, probs = 0.95),
    uu = quantile(value, probs = 0.05))


# d_sum$median_value[d_sum$median_value > fudge] <- fudge
# d_sum$u[d_sum$u > fudge] <- fudge
# d_sum$l[d_sum$l > fudge] <- fudge

d <- inner_join(d, d_last)

d$last_value[d$last_value > fudge] <- fudge
# d$value[d$value > fudge] <- fudge


cols <- brewer.pal(5, "RdBu")
cols <- c(cols[1], "grey50", cols[length(cols)])
g <- ggplot(d_sum, aes_string("year", "median_value")) +
  facet_grid(mp_name~variable, labeller = label_parsed) +
  geom_ribbon(aes(ymin = ll, ymax = uu), fill = "grey90") +
  geom_ribbon(aes(ymin = l, ymax = u), fill = "grey70") +
  ggsidekick::theme_sleek() +
  geom_line(lwd = 1.5) +
  coord_cartesian(ylim = c(0, 4)) +
  guides(colour = FALSE) +
  xlim(25, 50) +
  geom_hline(yintercept = 1,
    col = "black", lty = 2) +
  ylab("Value") + xlab("Year")
  # geom_line(data = filter(d, iter %in% c(1:10)),
  #   aes(y = value, group = iter),
  #   alpha = 0.4, colour = "blue")
  # scale_colour_gradientn(colours = cols,
  #     values = c(0, 0.8, 1.2, 3))
  # viridis::scale_colour_viridis()
g
```



```{r}
# get_contour <- function(df, x_variable, y_variable, prob = 0.8, n = 200, ...) {
#   x <- df[, c(x_variable, y_variable)] %>%
#     data.matrix()  %>%
#       coda::mcmc() %>%
#         emdbook::HPDregionplot(prob = prob, n = n, ...)
#
#   for (j in length(x)) x[[j]]$contour_group <- j
#
#   x <- x %>% lapply(as.data.frame) %>%
#     dplyr::bind_rows()
#
#   x <- dplyr::mutate(x, contour_group =
#     ifelse(!is.na(contour_group), contour_group, 1))
#
#   x[,c("x", "y", "contour_group")]
# }
#
# plot_polygons <- function(polygon_data, x_column, y_column,
#   xlab = "Variance", ylab = "Mean", prob = 0.75,
#   grouping = c("diversity_group"), ...) {
#   contours <- plyr::ddply(polygon_data, grouping,
#     function(x) get_contour(x, x_column, y_column, prob = prob))
# # We need unique IDs in case there are multiple polygons for one group
#   contours$id <- paste(contours$contour_group, contours[,grouping[1]])
#   polygon_data <- dplyr::mutate(polygon_data, id = 1)
#
#   p <- contours %>%
#     ggplot(aes_string("x", "y", group = "id", color = grouping[1],
#       fill = grouping[1]))
#
#   p <- p + geom_point(data = polygon_data, aes_string(x_column, y_column),
#     alpha = 0.1)
#   p <- p + geom_polygon(alpha = 0.3) +
#     viridis::scale_fill_viridis() +
#     viridis::scale_colour_viridis() +
#     theme_bw() +
#     xlab(xlab) + ylab(ylab)
#
#   if (length(grouping) > 1)
#     p <- p + facet_wrap(grouping[2])
#
#   print(p)
#   invisible(contours)
# }
#
# plot_polygons(data.frame(bbmsy = bbmsy, ffmsy = ffmsy, group = 1), "bbmsy", "ffmsy", grouping = "group")

```

VOI:

```{r}
#pdf("analysis/short-voi-om-b.pdf", width = 8, height = 8)
VOIplot(short_mse, Par="OM", nMP=5, YVar="B")
#dev.off()
```


# References
