# BEST PRACTICES FOR IMPLEMENTING A MANAGEMENT PROCEDURE APPROACH

@punt2016 reviewed best practices for MSE and identified five key steps in the process (Steps 2--6 below). In large part, the DLMtool software has been designed to allow practitioners to follow these steps, illustrated in Figure \@ref(fig:mse-chart) [@carruthers2018]. We also identify a critical first step (See Step 1 below), defining the decision context [@gregory2012 and Cox and Benson (unpublished)].

(ref:fig-mse-chart) The steps of the MSE process following @punt2016 as implemented in DLMtool. Adapted from @carruthers2018.

```{r mse-chart, fig.cap="(ref:fig-mse-chart)", out.width="6.3in"}
knitr::include_graphics(here::here("report/figure/mse-chart.pdf"))
```

<!-- TODO: figure out how to cite the Landmark report. We are not allowed to cite unpublished reports in CSAS docs (I don't think), but we could include it in a footnote. I tried doing a footnote but it didn't work. Anyway, here is the ref    ([^1]: Cox, S.P., and Benson, A.J. Unpublished. Roadmap to more sustainable Pacific herring fisheries in Canada: a step-by-step guide to the management strategy evaluation approach. Prepared for Pelagics Resource Management, Fisheries and Oceans Canada Pacific Region. Available on request.) -->


<!--When an MSE approach is applied in provision of management advice, decision-makers, stakeholders, and other interested parties (e.g., First Nations, Nongovernmental Organizations [NGOs], and academics) should be engaged throughout the process, particularly in defining the decision context, setting objectives and performance metrics, and selection of MPs [e.g., @cox2008a].-->

<!-- NOTE (RF): I commented the above paragraph out, it interrupts the flow and should be captured in the steps anyway. I think we need a "roles and responsibilities" heading. However, we  somewhere need to state that this report represents the elements of the framework as tested by Science but will require engagement when implemented in providing advice for specific stocks, as we haven't done a full engagement process. I think in the discussion.  -->


## STEP 1. DEFINE THE DECISION CONTEXT

Key questions to guide defining the decision context for MSE include:

* What is the the exact decision to be made?

* What is the timeframe for making the decision?

* What are the boundaries on the project and decision?

* What are specific roles and responsibilities of parties involved. Parties include science, management, First Nations, industry, academia, and/or non-governmental organizations (NGOs).

* How will the final decision be made? For example, it may be necessary to rank or weight objectives if there are large trade-offs with respect to performance against objectives.

Definition of the decision context is the role of managers, stakeholders, First Nations, and other key interested parties.

<!-- TODO: figure out how to cite the Landmark report. We are not allowed to cite unpublished reports in CSAS docs (I don't think), but we could include it in a footnote. I tried doing a footnote but it didn't work. Anyway, here is the ref    ([^1]: Cox, S.P., and Benson, A.J. Unpublished. Roadmap to more sustainable Pacific herring fisheries in Canada: a step-by-step guide to the management strategy evaluation approach. Prepared for Pelagics Resource Management, Fisheries and Oceans Canada Pacific Region. Available on request.) -->

## STEP 2. SELECTION OF OBJECTIVES AND PERFORMANCE METRICS

Clear management and fishery objectives and the performance metrics that measure them must be identified. Objectives may initially be high level and "strategic" (e.g., achieve sustainable fisheries, maintain economic prosperity, maintain cultural access) but these must be converted into operational "tactical" objectives that can be expressed as quantitative performance metrics [@punt2016]. Fully quantified objectives include a metric, the desired probability of success, and a time frame to achieve the objective (e.g., probability of maintaining the stock above the LRP is greater than 95%, throughout a 50 year period). 

Since the properties of underlying system represented by the OM are known exactly, a wide range of biological and economic metrics can be calculated from the OM [@carruthers2018]. However, having too many performance metrics can make the final decision process complex. Performance metrics should be chosen so they can be understood by decision-makers and participants, and to facilitate a tractable decision-making environment [@punt2016].

Objectives should be developed with the participation of managers, stakeholders, First Nations, and other interested parties.

## STEP 3. SELECTION OF UNCERTAINTIES/SPECIFICATION OF OPERATING MODELS

Uncertainties inherent in the underlying system are represented in the OM. Uncertainty in the OMs may be related to: the biology of the stock (e.g., growth, natural mortality, recruitment, migration); the dynamics of the fleet (e.g., targeting behaviour, selectivity of the fishing gear); the observation process (e.g., bias or imprecision in survey data or age/length composition data); and/or the implementation process (e.g., exceeding catch limits) [@carruthers2018]. 

Some of this uncertainty (e.g., range of values of natural mortality or other parameters) may be captured within a single OM by expressing distributions for these parameters. However, it is unlikely that the full range of uncertainties thought to influence the system can be captured in a single OM. Therefore, best practice recommends dividing MSE trials into a "reference set", utilizing a core set of of OMs that include the most important uncertainties (e.g., depletion of the stock or range of natural mortality values), and a "robustness set", representing other plausible OM formulations that represent alternative structural hypotheses (e.g., time-varying natural mortality or climate-driven recruitment [@rademeyer2007]). @punt2016 provide a list of factors which commonly have a large impact on MSE performance due to uncertainty (their Table 3). They also note that, in some cases, where the data used to parameterize the OM are in conflict (e.g., two indices of abundance are in conflict), the best practice may be to develop alternative OMs based on the different data sources.

Ideally, OMs should be calibrated to real data to ensure they can reproduce historical observations [e.g., @cox2008a; @forrest2018]. In very data-limited cases without reliable historical observations, this may not be possible. In these cases, best practice would be to develop a set of OMs that differ in terms of major uncertainties, especially related to stock productivity and current depletion level.

Development of OMs is principally the responsibility of science, although input from stakeholders, First Nations and other parties is desirable, especially with respect to identifying key uncertainties and ensuring plausibility of the OMs.

## STEP 4. IDENTIFICATION OF CANDIDATE MANAGEMENT PROCEDURES

Management procedures for fisheries managed by catch limits are generally either model-based, where data are integrated into a stock assessment model and outputs are used to calculate catch limits, or empirically-based, where data are used in an algorithm to directly determine the catch limit (e.g., adjustment of catch based on change in index of abundance) [@punt2016]. Data-limited MPs generally fall into the latter category, although simple stock assessment models such as surplus production models may sometimes be used. 

The scientific literature now reports many MPs for data-limited fisheries, more than 80 of which have been integrated into the DLMtool software [@carruthers2016; @carruthers2018]. Given the large number of MP options available, a screening step is desirable. For example, MPs that do not return a catch limit (e.g., spatial closures or effort-based MPs) can be immediately screened out if management requires a catch limit. After that, trial simulations may be used to screen out MPs that do not meet a basic set of requirements for a broad range of stocks (e.g., MPs that result in a high probability of stocks being below the LRP). Using trial simulations to screen out poorly-performing MPs is an example of "satisficing" [@miller2010], where MPs must meet a minimum-defined standard to be accepted. Satisficing criteria may be used at the screening stage and at the final MP selection stage. 

It is important to test only MPs for which information or data are available [@punt2016]. For example, data-limited MPs that rely on age-composition data or an estimate of current depletion may not be feasible for many BC groundfish stocks. While it is important to work with a managable set of MPs, it is also important not to screen too aggresively, to make sure good candidate MPs are not screened out early on.

In general, identification of available MPs is the role of Science. Managers, stakeholders and First Nations may be involved in determining desirable satisficing criteria, and may also provide input on feasibility of implementing some MPs. 

## STEP 5. SIMULATION OF THE APPLICATION OF THE MANAGEMENT PROCEDURES

Once the OM and MPs are fully specified, the MSE simulation trials can be run, following the process illustrated in Figure \@ref(fig:mse-chart). Essentially, all of the MPs are tested in in the simulation framework, using data generated by each OM. Critically, the simulations include feedback between the OM and the MP, where the OM generates data at each time step, which is used to apply the MP, which generates a catch recommendation, which is removed from the OM, which generates the next time step of data, and so forth until the projection period is complete. 

Typically a large number of replicate simulations are run for each OM-MP combination. Replicates may differ in terms of OM process error, observation errors and random draws from ranges of OM parameters, meaning that each replicate provides a different set of simulated data to the MPs. The number of replicates should be selected to ensure that performance metrics can be calculated with adequate precision [@punt2016], which may be indicated by MPs being consistently ranked in the same order throughout the simulated projection period [@carruthers2018]. The MSE should output enough information to calculate performance metrics for the MPs, and also to evaluate the behaviour and performance of the MSE itself (e.g., whether all trials converged, ranges of OM parameter values, and trajectories of key OM variables such as biomass and catch).

Running the simulations is the role of Science. Feedback from managers, stakeholders and First Nations should be sought throughout the process, to enable iterative refinment of the models and outputs [e.g., @cox2008a].

## STEP 6. PRESENTATION OF RESULTS AND SELECTION OF MANAGEMENT PROCEDURE

Selection of the "best" MP involves addressing trade-offs (e.g., between conservation and economic performance metrics), and therefore is the purview of managers, stakeholders, First Nations and interested parties [@punt2016]. Ultimately, selection of the best MP may be a subjective process, depending on the magnitude of trade-offs. It may be necessary to rank performance metrics in order of priority before the process starts. The role of science in this step is to ensure that results are clearly presented to decision-makers. Ideally this should include presentation of graphical outputs that enable clear comparison of MPs with respect to performance metrics and trade-offs [@punt2015].

A satisficing step may be used to screen out MPs that did not meet a minimum standard [@miller2010]. After this, MP selection may be an iterative process, where MPs and/or OMs are refined following examination of results [e.g., @cox2008a]. In cases where there is a reference and robustness set of OMs, it may be necessary to weight OMs on the basis of plausibility, although this may require a qualitative, expert-driven approach and may not be straightforward [@punt2016].

@carruthers2018 also discuss a final step, which is formal review of the selected MP once it has been implemented with real data. Formal review includes evaluation of whether the MP is performing as expected. For example, this could be done by comparing whether real relative abundance indices follow similar trajectories to those predicted by the simulations under the selected MP. In this document, we do not apply the MPs to real data, but recognize that ongoing review of the performance of MPs following their application is a critical component of MSE, where OMs and MPs may be continuously refined as new data become available [@cox2008a].

# METHODS: HOW THIS FRAMEWORK IMPLEMENTS BEST PRACTICES
We present the steps of a proposed simulation framework for selecting MPs based on trade-offs in performance amongst MPs, illustrated for two case-study fish stocks: Rex Sole (*Glyptocephalus zachirus*) and Shortraker Rockfish (*Sebastes borealis*) in Area 3CD (West Coast Vancouver Island). These stocks were selected because they are both considered data-limited and lack current assessment advice, and have contrasting life histories and data-availability. See Sections \@ref(shortraker-rockfish-case-study) and \@ref(rex-sole-case-study) for more details on each stock. The two case-studies are presented to illustrate the framework and its outputs. They are not intended for the provision of catch advice for these stocks at this time.

Sections \@ref(step-1-define-the-decision-context) to \@ref(step-6-presentation-of-results-and-selection-of-management-procedure) describe the methods of the framework, as it would be applied in the provision of catch advice, organised according to the six best-practice steps described in Section \@ref(best-practices-for-implementing-a-management-procedure-approach). 

<!-- TO DO: Need a map ... maybe later in the species summary sections -->


<!-- NOTE: RF has removed the periods in the subheadings below so they can be cross-referenced -->


## STEP 1 DEFINE THE DECISION CONTEXT

For quota-managed species, the decision to be made is which MP to use to determine catch limits for the period until the next available catch advice. The time-frame for making the decision should be stated in the request for science advice.

The boundaries on the project should be decided by a technical committee, convened for each assessment, and typically comprised of representatives from DFO Science, Fisheries Management, First Nations, commercial and recreational fishing representatives, NGOs and other interested parties, as required. Examples of project elements to be scoped include key uncertainties to be included and excluded in the OMs, data to be included and excluded, and explicit trade-offs to be considered. These will be discussed in more detail in the following sections.  

The final decision on which MP to use to determine catch limits should be made based on a consensus by the Regional Peer Review (RPR) committee, after review of the scientific content of the advice, including the structure and content of the OMs, and consideration of the relative performance of the MPs with respect to meeting stated objectives and trade-offs among performance metrics. The RPR committee will typically be comprised of the technical committee plus a much broader range of interested parties representing DFO Science, Fisheries Management, First Nations, commercial and recreational fishing representatives, NGOs and other interested parties.

The simulation framework tests the performance of specific MPs and will recommend a single catch limit from the final selected MP. The framework does not test posthoc adjustments to the catch limit recommended by an MP. This is in contrast to the decision tables presented in most Pacific Region groundfish stock assessments, where a range of possible catch limits with forecast of future stock status under each catch limit is provided for decision-making. Regardless of the framework used for advice, we note that it remains the purview of the Fisheries Minister to make posthoc adjustments to catch limits, based on cultural, social or economic considerations, in accordance with the *Fisheries Act* (Sections 6.1 (2) and 6.2(2)) 

## STEP 2 SELECTION OF OBJECTIVES AND PERFORMANCE METRICS

Here we describe a set of provisional objectives and associated performance metrics. In real applications of the framework objectives should be refined on a stock by stock basis, with advice from Fisheries Management, First Nations, commercial and recreational fishing representatives, NGOs and other affected parties. Other objectives could be added (e.g., cultural objectives), decided on a stock by stock basis.

Key provisional conservation objectives are guided by the PA Framework [@dfo2006; @dfo2009], elements of which are incorporated into the Fish Stocks provisions of the *Fisheries Act* (see Section \@ref(motivation)). Additional objectives related to fisheries yield and variability in annual fisheries yield are based on precedents in other DFO Pacific Region analyses [e.g., @cox2008a; @forrest2018; @cox2019].

We propose the following provisional tactical conservation and fisheries objectives:

1. Maintain stock status above the LRP in the long-term with high probability.

2. Maintain stock status above the USR with some probability

3. Avoid overfishing with some probability

4. Given the conservation objectives are achieved, maximize short- and
  long-term fisheries yield.
  
5. Given the conservation objectives are achieved, minimize variability
  in fisheries yield from year to year.
  
Objective 1 is implicit in Section 6.1 (1) of the *Fisheries Act* and explicit in Section 6.1(2) (see Section \@ref(motivation) of this document). Objectives 2 and 3 are interpretations of Section 6.1 (1) of the *Fisheries Act*, where it is stated that "the Minister shall implement measures to maintain major fish stocks at or above the level necessary to promote the sustainability of the stock". The term sustainability has many definitions. Here, we assume that the objective of maintaining the stock in the Healthy Zone (Figure \@ref(fig:pa-illustration)) with non-zero probability is consistent with the language of maintaing stocks at or above levels to promote sustainability. Here we use provisional values of LRP = 0.4 *SB*~MSY~ and USR = 0.8 *SB*~MSY~, suggested under the PA Framework [@dfo2009].

The specific probabilities assigned to successfully achieving each objective likely need consideration on a stock by stock basis. For Objective 1, international best practice suggests the probability of maintaining stocks above the LRP should be 90-95% [@sainsbury2008; @mcilgorm2013; @ices2018], while the probability of reaching a target biomass (e.g., the threshold to the Healthy Zone) can be lower at around 50% [@mcilgorm2013].

We provisionally suggest a 50-year projection period for the simulations, recognizing that shorter-lived stocks could use a shorter projection period, while longer-lived stocks may require a longer projection period. Applications for specific processes (e.g., the Committee on the Status of Endangered Wildlife in Canada, COSEWIC) may require a specific projection period based on metrics such as generation time.

We propose the following provisional performance metrics, where MSY refers to maximum sustainable yield, *SB*~MSY~ refers to equilibrium spawning biomass at MSY, and *F*~MSY~ refers to the fishing mortality that produces MSY over the long term:

1. LT P40: Probability SB > 0.4 *SB*~MSY~ (years 36--50)
2. LT P80: Probability SB > 0.8 *SB*~MSY~ (years 36--50)
3. PNOF: Probability of not overfishing P(F < *F*~MSY~) (years 1--50)
4. STY: Probability yield > 0.5 MSY (years 6--20)
5. LTY: Probability yield > 0.5 MSY (years 36--50)
6. AAVY: Probability AAVY (average annual variability in yield) < 0.2 (years 1--50)

LT P40 and LT P80 are conservation performance metrics measuring Objectives 1-2, respectively, measured over the long-term. PNOF ia a conservation performance metrics measuring Objective 3, measured over the whole projection period. LTY and STY  are economic metrics, representing Objective 4, measured in the short and long-term, respectively. AAV is an economic metric, representing Objective 5, measured over the whole projection period.

## STEP 3 SELECTION OF UNCERTAINTIES/SPECIFICATION OF OPERATING MODELS

We used the DLMtool software (@carruthers2018) to develop OMs for Shortraker Rockfish and Rex Sole. Dlmtool OMs are organised into four main components representing a real fished system: 1. population dynamics of the fish stock (e.g., growth, recruitment, mortality); fishery dynamics (e.g., selectivity, spatial targeting); observation processes (e.g., bias and precision in survey indices); and management implementation (e.g., catch limit overages). Parameters representing processes under the four components are described in detail in Section \@ref(the-dlmtool-operating-model).

* We recommend dividing operating models into reference and robustness sets [@rademeyer2007].

* DLMtool allows for incorporation of uncertainty in most OM parameters by specifying a distribution, typically a uniform distribution between two bounds.

* There can also be value in dividing the uncertainty into specific OMs to understand the applications of different scenarios.

The most important axes of uncertainty in reference sets that are likely across most stocks this framework will apply to include:

* Natural mortality (M)
* Steepness
* Depletion

Candidates for robustness sets may include:

* Predation scenarios (e.g., seal predation)
* Changes in availability of prey
* The effectiveness of or changes to closed areas such as Rockfish Conservation Areas (RCAs)
* Implementation error (actual catches are above or below the TAC)

DLMtool includes a very large number of parameters in the OM that can vary through time or be biased from one stochastic iteration to the next. To simplify the operating model and focus on what are likely the most important axes of uncertainty, we propose fixing a number of parameters to be unbiased and fixed through time unless this is an axis of uncertainty that makes sense to explore for specific stock (Appendix \@ref(app:default-slots)).

In the spirit of reproducible research and transparency, we suggest that the full specification of all parameters in the operating model be clearly documented in an implementation of the MP Framework. We demonstrate this in our case studies within this document (Appendix TODO and Appendix TODO).

*TODO: Abbreviate the following and put many more details into the appendix including the model description*

DLMtool includes an implementation of a Stock Reduction Analysis (REF), which is effectively a catch-at-age or surplus production model (depending on data inputs) that explores the combinations of historical fishing mortality and recruitment would be consistent with the observed data.

Kimura and Tagart (1982)
Walters et al. (2006)

The SRA implementation in MSEtool includes stochastic sampling of the specified operating model parameters. For example, if steepness is defined as being drawn from a uniform distribution between 0.6 and 0.9 across 200 stochastic iterations, then the SRA model will be fit 200 times, each time drawing a different value from that uniform distribution. Those sampled values of steepness are then stored and associated with the estimated parameters in the SRA model such as depletion and annual fishing mortality.

The SRA implementation in MSEtool can be conditioned on catch or effort timeseries. For most applications for groundfish in the Pacific Region, we suggest that conditioning on catch would make the most sense given that we tend to have a better handle on historical trajectories of catch than effort.

If catch are not available going back to unfished conditions, the user can specify a range of initial depletion associated with the first year of available catch.

The SRA function can take as input:

* indices of relative abundance or biomass
* age composition data
* length composition data
* mean length data

Given that in the Pacific Region we tend to have full-length composition data rather than just mean length data, the mean length data input is unlikely to be used within the MP Framework.

Although the SRA requires a complete time series of catch, it can make use of potentially sparse inputs of relative abundance and age or length composition data.

The SRA model can accommodate multiple indices of abundance and multiple fishing fleets.

Selectivity is fixed based on input values in the operating model if there are not any age or length composition data included.

The SRA model conditions the following OM parameters:

* unfished recruitment
* depletion
* relative fishing effort
* annual recruitment deviations
* selectivity parameters if age or length composition data are included

Details on the SRA model are available in Appendix TODO.

## STEP 4 IDENTIFICATION OF CANDIDATE MANAGEMENT PROCEDURES

We screened all MPs available in DLMtool as of November 2019 to consider their appropriateness for the MP Framework (Appendix \@ref(app:MPs)).

In summary, we excluded all MPs that required knowledge of:

* absolute abundance
* recent age composition data
* depletion
* steepness.

We excluded MPs that required knowledge of absolute abundance since they are unlikely to be cases where we have such knowledge in a data limited case. We excluded MPs that required recent age composition data because we intend this framework to be applied to stocks for which recent age competition data are not available. We excluded MPs that required knowledge of depletion and steepness since these are likely to be major axes of uncertainty stocks that the framework will be applied to. While it is necessary to explore these axes of uncertainty within the operating model, implementing an MP on real data would require choosing a value of depletion and steepness, which we argue would be a hard choice to justify and would be challenging to incorporate our true levels of uncertainty about and levels of bias in these parameters. 

DLMtool contains a number of MPs that make catch recommendations based on trends in mean fish length. These may be appropriate for some stocks, but ...

We suggest the empirical index-based MPs are likely to be most suitable for most data-limited groundfish stocks in the Pacific Region. This family of MPs generally try to maintain an index (usually a relative biomass or abundance index from a fisheries-independent survey) at some level by adjusting catch recommendations up or down as the index moves up or down. Different MPs include various levels of smoothing or thresholds and various methods of deriving a target index level. Such MPs have been considered as part of ... in the Pacific Region (REFs).

In addition to the empirical index-based MPs DLMtool and MSEtool include simple surplus production models, which may be considered for some stocks. We emphasize that these model-based MPs are simpler than the implementations often used in previous Pacific Region stock assessments. The point of using these models is to test their success at achieving the performance metrics and not the specific assumptions made within the implementations of the model.

DLMtool currently generates a single index of abundance for use in the data- or model-based MPs. In the future the software may include multiple indices of abundance; however, the vast majority of published data-limited MPs are based on single indices of abundance. This presents a conundrum for groundfish stocks in the Pacific Region since the trawl and hook and line fisheries-independent surveys that cover our coast do so on a biennial basis alternating amongst areas. We suggest the following solutions at the present time:

* Build and test operating models for areas associated with a single index. If these areas are considered simultaneously in a single application of the MP Framework then we suggest comparing performance of the MPs across all areas and, if possible, choosing an MP that performs reasonably well across all areas.

* Develop a single index by "stitching" multiple survey indices together, likely with the application of geostatistical spatiotemporal modeling [REFs].

Important to include reference MPs to bound the range of expected performance under scenarios such as: no fishing, perfect information (F_MSY_ and 0.75 F_MSY), and maintaining the status quo TAC.

### Broad types of MPs:

- Make into a table?

**Constant-catch MPs**

- no feedback!
- often fine for short-term projections
- longterm biomass will go towards equilibrium, which may be far lower (e.g. effectively 0) or higher than desired
- mostly included as a point of reference

**Index-ratio MPs**

- moving reference window
- simple concept
- has potential for pathological behaviour since it's not "anchored" to any fixed reference

**Index-slope MPs**

- moving reference window
- similar to "index ratio" types, but fits a regression of some kind and makes recommendations based on the slope

**Index-target MPs**

- fixed reference window
- likely to stabilize B and F and catch over time; at what level is the question
- makes the assumption that the specified target index is where we want the stock to be (which is tested against objectives but conditional on the operating model)
- target window may require judgement on a case-by-case basis

**Model-based MPs**

- here, SP models paired with HCRs
- more complex than data-based rules
- more theoretically sound; doesn't necessarily mean will perform well against objectives
- likely requires "tuning" of priors and possibly HCRs

Thoughts:

- MP development a rich area of research and is probably just in its infancy
- Beyond some minor adjustments to existing MPs, MP development is not the point of this report
- More MPs may be developed as part of the application of this framework (and are likely to be developed elsewhere in the literature) and could be included in the future
- No reason why an MP couldn't combine multiple aspects of the above, although there are advantages to simple and easy to understand MPs
- The MPs described in this report are a provisional library to build from
- MPs are meant to be followed until re-evaluated or the validity of the whole exercise is thrown off (obviously changes may need to be made given unanticipated surprises, but any major changes should also trigger an OM re-evaluation)

## STEP 5 SIMULATION OF THE APPLICATION OF THE MANAGEMENT PROCEDURES

* Once the OM and MPs are fully specified, DLMtool can be used to repeatedly simulate from the operating model and apply the management procedures.

* Replicates from run to run differ in  ...

* We suggest that sufficient replicates be run until the rank order of the various MPs across the various performance metrics within any given operating model remains consistent.

* We suggest only including replicates with MPs that converged (only applicable to the model-based MPs).

## STEP 6 PRESENTATION OF RESULTS AND SELECTION OF MANAGEMENT PROCEDURE

For this step we focus on developing a set of provisional visualizations that facilitate comparison of performance metrics across MPs and evaluation of trade-offs amongst them.

Spider plots [REF]. These illustrate performance trade-offs amongst the various MPs in a condensed visual fashion that lends itself to small multiples [REF] to explore a variety of OMs and MPs in a small amount of space.

Visualizations highlight the reference MPs for ease of comparison.

A performance metric Table/Figure. Shaded by probability of achieving that performance metric with rows ordered by performance metric starting with the leftmost performance metric and working across the columns to break ties. We think the shading helps to draw the eye to differences and similarities in performance.

Important to show historical trajectories of parameters such as: historical catch, historical recruitment, historical SSB, historical F, ... and any others that make particular sense for a given stock.

We developed projection plots that show the range of projected values in B/B[MSY], F/F[MSY], catch, and TAC recommendations along with example replicates for the various MPs.

We developed Kobe plots [REF] that illustrate the trade-off between F/F[MSY] and B/B[MSY] across replicates for the various MPs and emphasize the parameters space with the highest density via quantile kernel density estimate contour lines.

